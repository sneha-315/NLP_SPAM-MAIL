{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8697541,"sourceType":"datasetVersion","datasetId":5216120}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch","metadata":{"execution":{"iopub.status.busy":"2024-06-15T10:49:27.557150Z","iopub.execute_input":"2024-06-15T10:49:27.558114Z","iopub.status.idle":"2024-06-15T10:49:41.845158Z","shell.execute_reply.started":"2024-06-15T10:49:27.558079Z","shell.execute_reply":"2024-06-15T10:49:41.844015Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport csv\nimport time\nimport re, sys\nimport pandas as pd\n\nclass SpamClassifier(nn.Module):\n    def __init__(self, input_size):\n        super(SpamClassifier, self).__init__()\n        self.linear1 = nn.Linear(input_size, 16)\n        self.linear2 = nn.Linear(16, 1)\n        self.activation = nn.Sigmoid()\n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.activation(x)\n        x = self.linear2(x)\n        x = self.activation(x)\n        return x\n\nclass SpamDataset(Dataset):\n    def __init__(self, csv_file):\n        self.data = []\n        self.vectorizer = CountVectorizer()\n        messages = []\n        labels = []\n        with open(csv_file, \"r\") as f:\n            csv_reader = csv.reader(f)\n            for row in csv_reader:\n                if len(row) == 2:\n                    label, message = row\n                    messages.append(message)\n                    labels.append(int(label == 'spam'))  # Convert label to integer\n        # Convert messages to vectors\n        message_vectors = self.vectorizer.fit_transform(messages).toarray()\n        for vector, label in zip(message_vectors, labels):\n            self.data.append((vector, label))\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, idx):\n        message_vector, label = self.data[idx]\n        return torch.tensor(message_vector, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n\nclass Reprinter:\n    def __init__(self):\n        self.text = ''\n    def clear_line(self):\n        \"\"\"Clears the line before printing the new text.\"\"\"\n        sys.stdout.write('\\033[F')  # Move cursor up one line\n        sys.stdout.write('\\r' + ' ' * len(self.text))\n    def __call__(self, text):\n        \"\"\"Prints `text` and clears the previous line.\"\"\"\n        self.clear_line()\n        print(text, end='', flush=True)\n        self.text = text\n        sys.stdout.flush()\ndef train(model, train_data, train_loader, optimizer, loss_fn, epochs):\n    reprint = Reprinter()\n    start_time = time.time()  # Record the start time of training\n    for epoch in range(epochs):\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data = data.to(device)\n            target = target.to(device)\n            optimizer.zero_grad()\n            output = model(data).squeeze()  # Remove the extra dimension from output\n            loss = loss_fn(output, target)\n            loss.backward()\n            optimizer.step()\n            if batch_idx % 10 == 0:\n                reprint(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n                    epoch, batch_idx * len(data), len(train_data), 100.0 * batch_idx / len(train_loader), loss.item()\n                ))\n    end_time = time.time()  # Record the end time of training\n    elapsed_time = end_time - start_time  # Calculate the elapsed time\n    print(f\"\\nTraining took approximately {elapsed_time:.2f} seconds\")\n# Define the predict function\ndef predict(model, message):\n    # Convert the input message to a tensor\n    message_vector = torch.tensor(train_dataset.vectorizer.transform([message]).toarray(), dtype=torch.float32).to(device)\n    # Move the model to the appropriate device\n    model = model.to(device)\n    # Make the prediction\n    output = model(message_vector)\n    confidence = output.item() * 100.0\n    return confidence\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif torch.cuda.is_available():\n  deviceName = \"GPU\"\nelse:\n  deviceName = \"CPU\"\n\n# @title Training Settings\nchoice = \"Small (469 KB)\" # @param [\"Small (469 KB)\", \"Medium (10 MB)\"]\nmodel_name = \"spam_classifier_small\" # @param {type:\"string\"}\ntrain_now = True # @param {type:\"boolean\"}\nif train_now:\n  print(\"Using\", deviceName)\n  print(\"____________________________________________________________\")\ncsv.field_size_limit(sys.maxsize)\nif choice==\"Small (469 KB)\":\n  train_dataset = SpamDataset('/kaggle/input/spam-dataset/spam.csv')\nelif choice==\"Medium (10 MB)\":\n  train_dataset = SpamDataset('/kaggle/input/spam-dataset/spam_20.csv')\n#elif choice==\"Large (36 MB)\":\n#  train_dataset = SpamDataset(\"spam_large.csv\")\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ninput_size = len(train_dataset.vectorizer.get_feature_names_out())\nprint(f\"INPUT_SIZE FOR {model_name}: {input_size}\")\nmodel = SpamClassifier(input_size)\nmodel.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nloss_fn = nn.BCELoss()\nif train_now:\n  train(model, train_dataset, train_loader, optimizer, loss_fn, epochs=20)\n  # Save the model\n  torch.save(model.state_dict(), f\"{model_name}.pt\")\n\n# @title Inference { form-width: \"50%\" }\ntext_input = \"SEND ME MONEY\" # @param {type:\"string\"}\naccuracy = 3 # @param {type:\"slider\", min:1, max:13, step:1}\nmodel_select = \"spam_classifier_small\" # @param [\"spam_classifier_medium\", \"spam_classifier_small\"]\n# Load the model\n#if model_select == \"spam_classifier_small\":\n#  train_dataset = SpamDataset(\"spam.csv\")\n#elif model_select == \"spam_classifier_medium\":\n#  train_dataset = SpamDataset(\"spam_20.csv\")\nmodel = SpamClassifier(input_size)\nmodel.load_state_dict(torch.load(f\"{model_select}.pt\"))\n# Make a prediction\nmessage = text_input\nconfidence = predict(model, message)\nconfidence = round(confidence, accuracy)\nprint(f\"Confidence rate: {confidence}%\")","metadata":{"execution":{"iopub.status.busy":"2024-06-15T10:55:18.938302Z","iopub.execute_input":"2024-06-15T10:55:18.938699Z","iopub.status.idle":"2024-06-15T10:55:30.678173Z","shell.execute_reply.started":"2024-06-15T10:55:18.938645Z","shell.execute_reply":"2024-06-15T10:55:30.677101Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Using CPU\n____________________________________________________________\nINPUT_SIZE FOR spam_classifier_small: 8709\n                                                Train Epoch: 19 [5440/5573 (97%)]\tLoss: 0.010207F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\u001b[F\nTraining took approximately 10.08 seconds\nConfidence rate: 1.176%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}